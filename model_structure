digraph {
	graph [size="14.85,14.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1626304025552 [label="
 (1, 3)" fillcolor=darkolivegreen1]
	1612250994080 [label=AddmmBackward0]
	1612250994272 -> 1612250994080
	1626304023824 [label="fc2.bias
 (3)" fillcolor=lightblue]
	1626304023824 -> 1612250994272
	1612250994272 [label=AccumulateGrad]
	1612250994320 -> 1612250994080
	1612250994320 [label=AddmmBackward0]
	1612250994416 -> 1612250994320
	1626304023632 [label="fc1.bias
 (256)" fillcolor=lightblue]
	1626304023632 -> 1612250994416
	1612250994416 [label=AccumulateGrad]
	1612250994176 -> 1612250994320
	1612250994176 [label=ViewBackward0]
	1612250994560 -> 1612250994176
	1612250994560 [label=AvgPool2DBackward0]
	1612250994752 -> 1612250994560
	1612250994752 [label=LeakyReluBackward0]
	1612250994848 -> 1612250994752
	1612250994848 [label=CudnnBatchNormBackward0]
	1612250994944 -> 1612250994848
	1612250994944 [label=ConvolutionBackward0]
	1612250995136 -> 1612250994944
	1612250995136 [label=AvgPool2DBackward0]
	1612250995328 -> 1612250995136
	1612250995328 [label=LeakyReluBackward0]
	1612250995424 -> 1612250995328
	1612250995424 [label=CudnnBatchNormBackward0]
	1612250995520 -> 1612250995424
	1612250995520 [label=ConvolutionBackward0]
	1612250995712 -> 1612250995520
	1612250995712 [label=AvgPool2DBackward0]
	1612250995904 -> 1612250995712
	1612250995904 [label=LeakyReluBackward0]
	1612250996000 -> 1612250995904
	1612250996000 [label=CudnnBatchNormBackward0]
	1612250996096 -> 1612250996000
	1612250996096 [label=ConvolutionBackward0]
	1612250996288 -> 1612250996096
	1626304021424 [label="layer1.0.weight
 (32, 1, 5, 5)" fillcolor=lightblue]
	1626304021424 -> 1612250996288
	1612250996288 [label=AccumulateGrad]
	1612250996240 -> 1612250996096
	1626304021520 [label="layer1.0.bias
 (32)" fillcolor=lightblue]
	1626304021520 -> 1612250996240
	1612250996240 [label=AccumulateGrad]
	1612250996048 -> 1612250996000
	1626304021712 [label="layer1.1.weight
 (32)" fillcolor=lightblue]
	1626304021712 -> 1612250996048
	1612250996048 [label=AccumulateGrad]
	1612250995808 -> 1612250996000
	1626304021808 [label="layer1.1.bias
 (32)" fillcolor=lightblue]
	1626304021808 -> 1612250995808
	1612250995808 [label=AccumulateGrad]
	1612250995664 -> 1612250995520
	1626304022192 [label="layer2.0.weight
 (64, 32, 5, 5)" fillcolor=lightblue]
	1626304022192 -> 1612250995664
	1612250995664 [label=AccumulateGrad]
	1612250995616 -> 1612250995520
	1626304022288 [label="layer2.0.bias
 (64)" fillcolor=lightblue]
	1626304022288 -> 1612250995616
	1612250995616 [label=AccumulateGrad]
	1612250995472 -> 1612250995424
	1626304022384 [label="layer2.1.weight
 (64)" fillcolor=lightblue]
	1626304022384 -> 1612250995472
	1612250995472 [label=AccumulateGrad]
	1612250995232 -> 1612250995424
	1626304022480 [label="layer2.1.bias
 (64)" fillcolor=lightblue]
	1626304022480 -> 1612250995232
	1612250995232 [label=AccumulateGrad]
	1612250995088 -> 1612250994944
	1626304022864 [label="layer3.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1626304022864 -> 1612250995088
	1612250995088 [label=AccumulateGrad]
	1612250995040 -> 1612250994944
	1626304022960 [label="layer3.0.bias
 (128)" fillcolor=lightblue]
	1626304022960 -> 1612250995040
	1612250995040 [label=AccumulateGrad]
	1612250994896 -> 1612250994848
	1626304023056 [label="layer3.1.weight
 (128)" fillcolor=lightblue]
	1626304023056 -> 1612250994896
	1612250994896 [label=AccumulateGrad]
	1612250994656 -> 1612250994848
	1626304023152 [label="layer3.1.bias
 (128)" fillcolor=lightblue]
	1626304023152 -> 1612250994656
	1612250994656 [label=AccumulateGrad]
	1612250994464 -> 1612250994320
	1612250994464 [label=TBackward0]
	1612250994800 -> 1612250994464
	1626304023536 [label="fc1.weight
 (256, 22400)" fillcolor=lightblue]
	1626304023536 -> 1612250994800
	1612250994800 [label=AccumulateGrad]
	1612250994368 -> 1612250994080
	1612250994368 [label=TBackward0]
	1612250995184 -> 1612250994368
	1626304023728 [label="fc2.weight
 (3, 256)" fillcolor=lightblue]
	1626304023728 -> 1612250995184
	1612250995184 [label=AccumulateGrad]
	1612250994080 -> 1626304025552
}
